{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\graphrag_projects\\ire-evaluation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from evaluation.question_gen.question import Question\n",
    "\n",
    "from graphrag.model.community import Community\n",
    "from graphrag.model.community_report import CommunityReport\n",
    "from graphrag.model.entity import Entity\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_communities,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_reports,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.llm.text_utils import num_tokens\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.map_system_prompt import (\n",
    "    MAP_SYSTEM_PROMPT,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.reduce_system_prompt import (\n",
    "    REDUCE_SYSTEM_PROMPT,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating global search performance on different classes of questions\n",
    "\n",
    "This notebook shows an example of using the evaluation package to generate global search answers for an experiment that evaluate the global search performance for different classes of questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"AP_OPENAI_API_KEY\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "llm_model = \"gpt-4o-2024-05-13\"\n",
    "llm_deployment_name = \"gpt-4o-2024-05-13\"\n",
    "\n",
    "llm_init_params = {\n",
    "    \"api_key\": api_key,\n",
    "    \"api_version\": api_version,\n",
    "    \"model\": llm_model,\n",
    "    \"deployment_name\": llm_deployment_name,\n",
    "    \"api_type\": OpenaiApiType.OpenAI,\n",
    "    \"max_retries\": 50,\n",
    "}\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"o200k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating global search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DATA_TOKENS = 8000\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "COMMUNITY_TABLE = \"create_final_communities\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "OUTPUT_DIR = f\"./answers/autoq/v1/{llm_model}\"\n",
    "QUESTION_DIR = \"./questions/autoq/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(input_dir: str, community_level: int):\n",
    "    full_input_dir = f\"output/{input_dir}/artifacts\"\n",
    "    entity_df = pd.read_parquet(f\"{full_input_dir}/{ENTITY_TABLE}.parquet\")\n",
    "    report_df = pd.read_parquet(f\"{full_input_dir}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "    entity_embedding_df = pd.read_parquet(\n",
    "        f\"{full_input_dir}/{ENTITY_EMBEDDING_TABLE}.parquet\"\n",
    "    )\n",
    "    community_df = pd.read_parquet(f\"{full_input_dir}/{COMMUNITY_TABLE}.parquet\")\n",
    "\n",
    "    communities = read_indexer_communities(\n",
    "        final_communities=community_df,\n",
    "        final_nodes=entity_df,\n",
    "        final_community_reports=report_df,\n",
    "    )\n",
    "    reports = read_indexer_reports(\n",
    "        final_community_reports=report_df,\n",
    "        final_nodes=entity_df,\n",
    "        community_level=community_level,\n",
    "        dynamic_selection=True,\n",
    "    )\n",
    "    entities = read_indexer_entities(\n",
    "        final_nodes=entity_df,\n",
    "        final_entities=entity_embedding_df,\n",
    "        community_level=community_level,\n",
    "    )\n",
    "    print(f\"Report records: {len(reports)}\")\n",
    "    # print(report_df.head())\n",
    "    return reports, entities, communities\n",
    "\n",
    "\n",
    "def create_search_engine(\n",
    "    reports: list[CommunityReport],\n",
    "    entities: list[Entity],\n",
    "    communities: list[Community],\n",
    "    max_data_tokens: int = MAX_DATA_TOKENS,\n",
    "    max_map_output_tokens: int = 1000,\n",
    "    max_reduce_output_tokens: int = 2000,\n",
    "    map_system_prompt: str = MAP_SYSTEM_PROMPT,\n",
    "    reduce_system_prompt: str = REDUCE_SYSTEM_PROMPT,\n",
    "):\n",
    "    \"\"\"create global search engine\"\"\"\n",
    "\n",
    "    # initialize GPT-4o mini for dynamic search\n",
    "    mini_llm = ChatOpenAI(**{\n",
    "        \"api_key\": api_key,\n",
    "        \"api_version\": api_version,\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"deployment_name\": \"gpt-4o-mini\",\n",
    "        \"api_type\": OpenaiApiType.OpenAI,\n",
    "        \"max_retries\": 50,\n",
    "    })\n",
    "\n",
    "    context_builder = GlobalCommunityContext(\n",
    "        community_reports=reports,\n",
    "        entities=entities,\n",
    "        communities=communities,\n",
    "        llm=mini_llm,\n",
    "        token_encoder=token_encoder,\n",
    "        dynamic_selection=True,\n",
    "        dynamic_selection_params={\n",
    "            \"keep_parent\": False,\n",
    "            \"num_repeats\": 1,\n",
    "            \"use_summary\": False,\n",
    "            \"concurrent_coroutines\": 16,\n",
    "            \"rating_threshold\": 1,\n",
    "            \"start_with_root\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    context_builder_params = {\n",
    "        \"use_community_summary\": False,\n",
    "        \"shuffle_data\": True,\n",
    "        \"include_community_rank\": True,\n",
    "        \"min_community_rank\": 0,\n",
    "        \"community_rank_name\": \"rank\",\n",
    "        \"include_community_weight\": False,\n",
    "        \"community_weight_name\": \"occurrence weight\",\n",
    "        \"normalize_community_weight\": False,\n",
    "        \"max_tokens\": MAX_DATA_TOKENS,\n",
    "        \"context_name\": \"Reports\",\n",
    "    }\n",
    "\n",
    "    map_llm_params = {\n",
    "        \"max_tokens\": max_map_output_tokens,\n",
    "        \"temperature\": 0.0,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    }\n",
    "\n",
    "    reduce_llm_params = {\n",
    "        \"max_tokens\": max_reduce_output_tokens,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    llm = ChatOpenAI(**llm_init_params)\n",
    "\n",
    "    search_engine_configs = {\n",
    "        \"llm\": llm,\n",
    "        \"context_builder\": context_builder,\n",
    "        \"token_encoder\": token_encoder,\n",
    "        \"max_data_tokens\": max_data_tokens,\n",
    "        \"map_llm_params\": map_llm_params,\n",
    "        \"reduce_llm_params\": reduce_llm_params,\n",
    "        \"map_system_prompt\": map_system_prompt,\n",
    "        \"reduce_system_prompt\": reduce_system_prompt,\n",
    "        \"context_builder_params\": context_builder_params,\n",
    "        \"concurrent_coroutines\": 16,\n",
    "        \"allow_general_knowledge\": False,\n",
    "        \"json_mode\": True,\n",
    "        \"response_type\": \"multiple paragraphs\",\n",
    "    }\n",
    "    search_engine = GlobalSearch(**search_engine_configs)\n",
    "    return search_engine, search_engine_configs, llm_init_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from evaluation.answer_gen.search_answer_gen import (\n",
    "    AnswerType,\n",
    "    GlobalSearchAnswerGenerator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QuestionSet:\n",
    "    name: str\n",
    "    questions: list[Question]\n",
    "\n",
    "\n",
    "def load_question_set(question_dir: str, question_name: str) -> QuestionSet:\n",
    "    question_file = f\"{question_dir}/{question_name}.json\"\n",
    "\n",
    "    # load question json file\n",
    "    questions: list[Question] = []\n",
    "    with open(question_file, \"r\") as f:\n",
    "        question_json = json.load(f)\n",
    "        for question in question_json:\n",
    "            questions.append(Question(id=question[\"id\"], text=question[\"text\"]))\n",
    "    return QuestionSet(name=question_name, questions=questions)\n",
    "\n",
    "\n",
    "async def generate_answers(\n",
    "    question_set: QuestionSet,\n",
    "    input_dir: str,\n",
    "    community_level: int,\n",
    "    max_data_tokens: int,\n",
    "    max_map_output_tokens: int,\n",
    "    max_reduce_output_tokens: int,\n",
    "    map_prompt: dict,\n",
    "    reduce_prompt: dict,\n",
    "):\n",
    "    reports, entities, communities = prep_data(input_dir, community_level)\n",
    "    search_engine, search_engine_configs, llm_init_params = create_search_engine(\n",
    "        reports=reports,\n",
    "        entities=entities,\n",
    "        communities=communities,\n",
    "        max_data_tokens=max_data_tokens,\n",
    "        max_map_output_tokens=max_map_output_tokens,\n",
    "        max_reduce_output_tokens=max_reduce_output_tokens,\n",
    "        map_system_prompt=map_prompt[\"prompt\"],\n",
    "        reduce_system_prompt=reduce_prompt[\"prompt\"],\n",
    "    )\n",
    "    answer_generator = GlobalSearchAnswerGenerator(\n",
    "        search_engine=search_engine,\n",
    "        search_engine_configs=search_engine_configs,\n",
    "        llm_init_params=llm_init_params,\n",
    "        concurrent_coroutines=2,\n",
    "    )\n",
    "\n",
    "    # generate main answers\n",
    "    print(\"GENERATING MAIN ANSWERS...\")\n",
    "    candidate_answers = await answer_generator.agenerate(\n",
    "        questions=question_set.questions, answer_type=AnswerType.CANDIDATE_ANSWER\n",
    "    )\n",
    "    # calculate average completion time\n",
    "    completion_times = []\n",
    "    build_context_input_tokens, build_context_output_tokens = [], []\n",
    "    map_reduce_input_tokens, map_reduce_output_tokens = [], []\n",
    "    for answer in candidate_answers:\n",
    "        if answer.generated_answer.response.strip() != \"\":\n",
    "            completion_times.append(answer.generated_answer.completion_time)\n",
    "            build_context_input_tokens.append(answer.generated_answer.prompt_tokens['build_context'])\n",
    "            build_context_output_tokens.append(answer.generated_answer.output_tokens['build_context'])\n",
    "            map_reduce_input_tokens.append(answer.generated_answer.prompt_tokens['map'])\n",
    "            map_reduce_output_tokens.append(answer.generated_answer.output_tokens['map'])\n",
    "            map_reduce_input_tokens.append(answer.generated_answer.prompt_tokens['reduce'])\n",
    "            map_reduce_output_tokens.append(answer.generated_answer.output_tokens['reduce'])\n",
    "\n",
    "\n",
    "    results = {\n",
    "        \"input_dir\": input_dir,\n",
    "        \"community_level\": community_level,\n",
    "        \"max_data_tokens\": max_data_tokens,\n",
    "        \"max_map_output_tokens\": max_map_output_tokens,\n",
    "        \"max_reduce_output_tokens\": max_reduce_output_tokens,\n",
    "        \"map_prompt\": map_prompt,\n",
    "        \"reduce_prompt\": reduce_prompt,\n",
    "        \"map_prompt_type\": map_prompt[\"type\"],\n",
    "        \"reduce_system_prompt_type\": reduce_prompt[\"type\"],\n",
    "        \"mean_completion_time\": np.mean(completion_times),\n",
    "        \"std_completion_time\": np.std(completion_times),\n",
    "        \"total_input_tokens\": sum([np.sum(build_context_input_tokens), np.sum(map_reduce_input_tokens)]),\n",
    "        \"total_output_tokens\": sum([np.sum(build_context_output_tokens), np.sum(map_reduce_output_tokens)]),\n",
    "        \"num_valid_answers\": len([\n",
    "            a for a in candidate_answers if a.generated_answer.response.strip() != \"\"\n",
    "        ]),\n",
    "        \"answers\": candidate_answers,\n",
    "    }\n",
    "\n",
    "    file_name = f\"candidate_answers.pkl\"\n",
    "    FINAL_OUTPUT_DIR = f\"{OUTPUT_DIR}/{input_dir}/{question_set.name}/global_search_fixed_community_filtering_{community_level}\"\n",
    "    if not os.path.exists(FINAL_OUTPUT_DIR):\n",
    "        os.makedirs(FINAL_OUTPUT_DIR)\n",
    "\n",
    "    with open(f\"./{FINAL_OUTPUT_DIR}/{file_name}\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    simplified_results = []\n",
    "    for qa in candidate_answers:\n",
    "        simplified_results.append({\n",
    "            \"question_id\": qa.question.id,\n",
    "            \"question_text\": qa.question.text,\n",
    "            \"answer\": qa.generated_answer.response.strip(),\n",
    "        })\n",
    "        if qa.generated_answer.response.strip() == \"\":\n",
    "            print(f\"Empty answer for question: {qa.question.text}\")\n",
    "\n",
    "    with open(f\"./{FINAL_OUTPUT_DIR}/candidate_answers_text.json\", \"w\") as f:\n",
    "        json.dump(simplified_results, f, indent=4)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = [\n",
    "    \"20240910-222417-exp7\",\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"data_global_questions\",\n",
    "    # \"data_local_questions\",\n",
    "    # \"activity_global_questions\",\n",
    "    # \"activity_local_questions\",\n",
    "]\n",
    "\n",
    "max_data_tokens_options = [MAX_DATA_TOKENS]\n",
    "community_levels = [1]\n",
    "max_map_output_tokens_options = [1000]\n",
    "max_reduce_output_tokens_options = [2000]\n",
    "map_prompts = [{\"prompt\": MAP_SYSTEM_PROMPT, \"type\": \"default\"}]\n",
    "reduce_prompts = [{\"prompt\": REDUCE_SYSTEM_PROMPT, \"type\": \"default\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing combination: 0\n"
     ]
    }
   ],
   "source": [
    "# get all combinations of parameters using itertools\n",
    "from itertools import product\n",
    "\n",
    "question_sets = []\n",
    "for question in questions:\n",
    "    question_set = load_question_set(QUESTION_DIR, question)\n",
    "    question_sets.append(question_set)\n",
    "\n",
    "combinations = list(\n",
    "    product(\n",
    "        question_sets,\n",
    "        input_dirs,\n",
    "        community_levels,\n",
    "        max_data_tokens_options,\n",
    "        max_map_output_tokens_options,\n",
    "        max_reduce_output_tokens_options,\n",
    "        map_prompts,\n",
    "        reduce_prompts,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "for index, combination in enumerate(combinations):\n",
    "    run_stats = []\n",
    "    print(f\"Processing combination: {index}\")\n",
    "    results = await generate_answers(*combination)\n",
    "    run_stats.append({\n",
    "        \"question_set\": combination[0].name,\n",
    "        \"input_dir\": combination[1],\n",
    "        \"llm_model\": llm_model,\n",
    "        \"community_level\": combination[2],\n",
    "        \"avg_completion_time\": results[\"mean_completion_time\"],\n",
    "        \"std_completion_time\": results[\"std_completion_time\"],\n",
    "        \"total_input_tokens\": results[\"total_input_tokens\"],\n",
    "        \"total_output_tokens\": results[\"total_output_tokens\"],\n",
    "        \"num_valid_answers\": results[\"num_valid_answers\"],\n",
    "    })\n",
    "    stats_df = pd.DataFrame(run_stats)\n",
    "    stats_df.to_csv(\n",
    "        f\"{OUTPUT_DIR}/global_search_fixed_community_filtering_{combination[0].name}_community_{combination[2]}_stats.csv\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
